{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPn34uzgXeaKslMZqm3YcvC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lawapaul/AI_Agentic_DL/blob/model-comparison/notebooks/baseline/Baseline_CNN_Full_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running 1D CNN"
      ],
      "metadata": {
        "id": "mnukazPiKoYY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruAlzIWO4JZ3",
        "outputId": "f6bca480-dc5d-4df2-de0b-8eb419a78834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AI_Agentic_DL' already exists and is not an empty directory.\n",
            "/content/AI_Agentic_DL\n",
            "Already on 'model-comparison'\n",
            "Your branch is up to date with 'origin/model-comparison'.\n",
            "Requirement already satisfied: tensorflow>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.19.0)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: shap>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.50.0)\n",
            "Requirement already satisfied: kagglehub>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.3.13)\n",
            "Requirement already satisfied: transformers>=4.35.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (5.0.0)\n",
            "Requirement already satisfied: accelerate>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.12.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.9.0+cu128)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (5.29.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.5.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 2)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (4.67.3)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.1.0->-r requirements.txt (line 8)) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.24.0->-r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.46.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (1.5.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap>=0.42.0->-r requirements.txt (line 7)) (0.43.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->-r requirements.txt (line 11)) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers>=4.35.0->-r requirements.txt (line 9)) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.1.2)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (26.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lawapaul/AI_Agentic_DL.git\n",
        "%cd AI_Agentic_DL\n",
        "!git checkout model-comparison\n",
        "!pip install -r requirements.txt\n",
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVW6vs3b6tEa",
        "outputId": "dba65170-3a74-4b79-d76f-b123173c4c5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  main\u001b[m\n",
            "* \u001b[32mmodel-comparison\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg22_C2W-jz6",
        "outputId": "e48c3684-a25f-4247-c5f8-eec2d58645ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNgOpnAj6ut4",
        "outputId": "f3542a9a-a71f-48fe-bc9b-9e9eabc5acbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn_model.py\t    __init__.py       __pycache__\n",
            "hybrid_cnn_lstm.py  model_factory.py  trainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwfZWBfA7nlw",
        "outputId": "2e7379d1-8f62-498b-d4fd-98b5996a846a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 1.44 KiB | 1.44 MiB/s, done.\n",
            "From https://github.com/lawapaul/AI_Agentic_DL\n",
            "   040a50d..d2bf7c4  model-comparison -> origin/model-comparison\n",
            "Updating 040a50d..d2bf7c4\n",
            "Fast-forward\n",
            " explainability/shap_explainer.py | 235 \u001b[32m++++++++++++++++++++++\u001b[m\u001b[31m-----------------\u001b[m\n",
            " 1 file changed, 132 insertions(+), 103 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLU5i64o78_r",
        "outputId": "335d2928-1f42-4121-847e-578c9823f4cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (26.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "dataset_path = kagglehub.dataset_download(\"solarmainframe/ids-intrusion-csv\")\n",
        "print(\"Dataset downloaded to:\", dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boKXkwsO7_D_",
        "outputId": "6f5a9495-d15b-4a40-8bf3-6ac824a500ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'ids-intrusion-csv' dataset.\n",
            "Dataset downloaded to: /kaggle/input/ids-intrusion-csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pipeline.py --samples 5 --retrain --model cnn --no-llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w42QI74x-_Cf",
        "outputId": "c0adf482-112f-4628-cbe1-23feab65c1e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-15 16:17:13.012175: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771172233.032921   10458 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771172233.039882   10458 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771172233.056334   10458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771172233.056358   10458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771172233.056362   10458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771172233.056365   10458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\n",
            "======================================================================\n",
            "AUTONOMOUS EXPLAINABLE INTRUSION DETECTION SYSTEM\n",
            "======================================================================\n",
            "\n",
            "[STEP 1/6] Loading and Preprocessing Data\n",
            "----------------------------------------------------------------------\n",
            "Loading IDS dataset...\n",
            "Found dataset path: /root/.cache/kagglehub/datasets/solarmainframe/ids-intrusion-csv/versions/1\n",
            "Loading CSV file: /root/.cache/kagglehub/datasets/solarmainframe/ids-intrusion-csv/versions/1/02-14-2018.csv\n",
            "Dataset loaded: 1048575 samples, 80 columns\n",
            "\n",
            "=== Starting Preprocessing ===\n",
            "Separated labels: 1048575 samples\n",
            "Feature columns: 79\n",
            "Unique attack types: 3\n",
            "Attack distribution:\n",
            "Label\n",
            "Benign            667626\n",
            "FTP-BruteForce    193360\n",
            "SSH-Bruteforce    187589\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Converting features to numeric...\n",
            "Converted 79 columns to numeric\n",
            "\n",
            "Dropping fully-NaN columns...\n",
            "Columns after dropping fully-NaN: 78\n",
            "\n",
            "Dropping rows with NaN values...\n",
            "Rows before: 1048575, after: 1046298\n",
            "Dropped 2277 rows with NaN\n",
            "\n",
            "Final feature count: 78\n",
            "\n",
            "Encoding labels...\n",
            "Label mapping: {0: 'Benign', 1: 'FTP-BruteForce', 2: 'SSH-Bruteforce'}\n",
            "\n",
            "Handling infinity and extreme values...\n",
            "Dropped 1547 rows with infinity values\n",
            "/content/AI_Agentic_DL/data/loader.py:178: FutureWarning: Downcasting behavior in Series and DataFrame methods 'where', 'mask', and 'clip' is deprecated. In a future version this will not infer object dtypes or cast all-round floats to integers. Instead call result.infer_objects(copy=False) for object inference, or cast round floats explicitly. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  X[col] = X[col].clip(lower, upper)\n",
            "Cleaned data shape: (1044751, 78)\n",
            "\n",
            "Scaling features...\n",
            "Features scaled: mean=-0.0000, std=0.9337\n",
            "\n",
            "Splitting data: 80% train, 20% test\n",
            "Train set: 835800 samples\n",
            "Test set: 208951 samples\n",
            "\n",
            "Reshaping for 1D CNN...\n",
            "Train shape: (835800, 78, 1)\n",
            "Test shape: (208951, 78, 1)\n",
            "\n",
            "=== Preprocessing Complete ===\n",
            "\n",
            "✓ Data loaded successfully\n",
            "  Training samples: 835800\n",
            "  Test samples: 208951\n",
            "  Features: 78\n",
            "  Classes: 3\n",
            "\n",
            "[STEP 2/6] Deep Learning Model\n",
            "----------------------------------------------------------------------\n",
            "Training new CNN model...\n",
            "\n",
            "=== Training IDS CNN Model ===\n",
            "Training samples: 835800\n",
            "Validation samples: 208951\n",
            "Batch size: 128\n",
            "Max epochs: 5\n",
            "Input shape after reshape: (835800, 78, 1)\n",
            "2026-02-15 16:17:41.838156: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1771172261.839683   10458 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2026-02-15 16:17:43.568470: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 260769600 exceeds 10% of free system memory.\n",
            "2026-02-15 16:17:43.845902: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 260769600 exceeds 10% of free system memory.\n",
            "Epoch 1/5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1771172268.683435   10607 service.cc:152] XLA service 0x7a3b54002720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1771172268.683468   10607 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "I0000 00:00:1771172269.457496   10607 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2026-02-15 16:17:51.669212: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng12{k11=2} for conv %cudnn-conv-bias-activation.38 = (f32[128,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,1,78]{3,2,1,0} %bitcast.19956, f32[256,256,1,3]{3,2,1,0} %bitcast.19960, f32[256]{0} %bitcast.23674), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 16:17:52.663503: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.994389547s\n",
            "Trying algorithm eng12{k11=2} for conv %cudnn-conv-bias-activation.38 = (f32[128,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,1,78]{3,2,1,0} %bitcast.19956, f32[256,256,1,3]{3,2,1,0} %bitcast.19960, f32[256]{0} %bitcast.23674), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 16:17:52.769590: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 20.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2026-02-15 16:17:54.056308: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=2} for conv %cudnn-conv-bw-input.5 = (f32[128,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,1,78]{3,2,1,0} %bitcast.22216, f32[256,256,1,3]{3,2,1,0} %bitcast.22220), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 16:17:54.859449: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.80322778s\n",
            "Trying algorithm eng4{k11=2} for conv %cudnn-conv-bw-input.5 = (f32[128,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,1,78]{3,2,1,0} %bitcast.22216, f32[256,256,1,3]{3,2,1,0} %bitcast.22220), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 16:17:55.537572: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 16:17:55.859670: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.5 = (f32[128,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,1,78]{3,2,1,0} %bitcast.22216, f32[256,256,1,3]{3,2,1,0} %bitcast.22220), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 16:17:56.055003: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 16:17:56.286136: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.42653598s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.5 = (f32[128,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,1,78]{3,2,1,0} %bitcast.22216, f32[256,256,1,3]{3,2,1,0} %bitcast.22220), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 16:17:57.758882: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 16:17:58.116001: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 16:17:58.545724: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 16:17:58.762390: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 16:18:01.711417: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng18{k11=0} for conv %cudnn-conv-bw-filter.10 = (f32[256,256,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,1,78]{3,2,1,0} %bitcast.19956, f32[128,256,1,78]{3,2,1,0} %bitcast.22216), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 16:18:01.858797: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.147471863s\n",
            "Trying algorithm eng18{k11=0} for conv %cudnn-conv-bw-filter.10 = (f32[256,256,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,1,78]{3,2,1,0} %bitcast.19956, f32[128,256,1,78]{3,2,1,0} %bitcast.22216), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 16:18:01.967350: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2026-02-15 16:18:02.243730: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "I0000 00:00:1771172288.995417   10607 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m6527/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9835 - loss: 0.04472026-02-15 16:20:44.362703: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 19.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2026-02-15 16:20:47.208072: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng18{k11=0} for conv %cudnn-conv-bw-filter.10 = (f32[256,256,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[88,256,1,78]{3,2,1,0} %bitcast.19956, f32[88,256,1,78]{3,2,1,0} %bitcast.22216), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 16:20:47.293596: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.085623664s\n",
            "Trying algorithm eng18{k11=0} for conv %cudnn-conv-bw-filter.10 = (f32[256,256,1,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[88,256,1,78]{3,2,1,0} %bitcast.19956, f32[88,256,1,78]{3,2,1,0} %bitcast.22216), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 16:20:47.363831: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2026-02-15 16:20:47.862171: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "\u001b[1m6530/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9835 - loss: 0.0447\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98699, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m6530/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 27ms/step - accuracy: 0.9835 - loss: 0.0447 - val_accuracy: 0.9870 - val_loss: 0.0787 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m6529/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0016\n",
            "Epoch 2: val_accuracy improved from 0.98699 to 0.99976, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m6530/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9998 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m6529/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0011\n",
            "Epoch 3: val_accuracy did not improve from 0.99976\n",
            "\u001b[1m6530/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9998 - val_loss: 0.0015 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m6529/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 8.5648e-04\n",
            "Epoch 4: val_accuracy did not improve from 0.99976\n",
            "\u001b[1m6530/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 8.5649e-04 - val_accuracy: 0.9667 - val_loss: 0.0939 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m6529/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 9.3999e-04\n",
            "Epoch 5: val_accuracy improved from 0.99976 to 0.99993, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m6530/6530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 9.3996e-04 - val_accuracy: 0.9999 - val_loss: 7.5500e-04 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.0008\n",
            "Test Accuracy: 0.9999\n",
            "\n",
            "Training history plot saved to: training_history.png\n",
            "\n",
            "=== Detailed Classification Report ===\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "        Benign       1.00      1.00      1.00    132762\n",
            "FTP-BruteForce       1.00      1.00      1.00     38671\n",
            "SSH-Bruteforce       1.00      1.00      1.00     37518\n",
            "\n",
            "      accuracy                           1.00    208951\n",
            "     macro avg       1.00      1.00      1.00    208951\n",
            "  weighted avg       1.00      1.00      1.00    208951\n",
            "\n",
            "\n",
            "✓ Model ready for inference\n",
            "\n",
            "[STEP 3/6] Initializing Explainability (SHAP)\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "=== Initializing SHAP Explainer ===\n",
            "Background data shape: (100, 78, 1)\n",
            "Number of features: 78\n",
            "SHAP GradientExplainer initialized successfully\n",
            "\n",
            "✓ SHAP explainer initialized\n",
            "\n",
            "[STEP 4/6] Initializing LLM Reasoning\n",
            "----------------------------------------------------------------------\n",
            "LLM disabled\n",
            "\n",
            "[STEP 5/6] Initializing Risk Scorer\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "=== Risk Scorer Initialized ===\n",
            "Confidence weight: 0.4\n",
            "SHAP weight: 0.3\n",
            "Severity weight: 0.3\n",
            "\n",
            "✓ Risk scorer initialized\n",
            "\n",
            "[STEP 6/6] Initializing Decision Agent\n",
            "----------------------------------------------------------------------\n",
            "\\n=== Initializing Decision Agent ===\n",
            "Using rule-based decision logic\n",
            "\n",
            "✓ Decision agent initialized\n",
            "\n",
            "======================================================================\n",
            "PIPELINE READY - PROCESSING SAMPLES\n",
            "======================================================================\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: keras_tensor\n",
            "Received: inputs=['Tensor(shape=(1, 78, 1))']\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: keras_tensor\n",
            "Received: inputs=['Tensor(shape=(50, 78, 1))']\n",
            "  warnings.warn(msg)\n",
            "\n",
            "✓ Results saved to: ids_results_20260215_163322.json\n",
            "\n",
            "PIPELINE COMPLETE\n",
            "Processed 5 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pushing"
      ],
      "metadata": {
        "id": "tT6UvN52Krlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p notebooks/baseline\n",
        "!mv Baseline_CNN_Full_Pipeline.ipynb notebooks/baseline/Baseline_CNN_Full_Pipeline.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7bnnN9gKtN7",
        "outputId": "d8056510-97da-4379-d82c-8a17f4022247"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'Baseline_CNN_Full_Pipeline.ipynb': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}