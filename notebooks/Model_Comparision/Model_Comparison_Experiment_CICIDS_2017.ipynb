{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t6Ked6v3Vmw"
      },
      "source": [
        "#Setting up the Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSzA0pPLMGrd",
        "outputId": "47032fdf-9879-49d1-d102-2ad71baba348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'AI_Agentic_DL'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 169 (delta 67), reused 124 (delta 33), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (169/169), 80.70 KiB | 1.30 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n",
            "/content/AI_Agentic_DL\n",
            "Branch 'model-comparison' set up to track remote branch 'model-comparison' from 'origin'.\n",
            "Switched to a new branch 'model-comparison'\n",
            "Requirement already satisfied: tensorflow>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.19.0)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: shap>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.50.0)\n",
            "Requirement already satisfied: kagglehub>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.3.13)\n",
            "Requirement already satisfied: transformers>=4.35.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (5.0.0)\n",
            "Requirement already satisfied: accelerate>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.12.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.9.0+cu128)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (5.29.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.78.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.5.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 2)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (4.67.3)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.1.0->-r requirements.txt (line 8)) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (3.21.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.24.0->-r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.46.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (1.5.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap>=0.42.0->-r requirements.txt (line 7)) (0.43.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.10.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->-r requirements.txt (line 11)) (3.0.3)\n",
            "Requirement already satisfied: typer>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers>=4.35.0->-r requirements.txt (line 9)) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.23.0->typer-slim->transformers>=4.35.0->-r requirements.txt (line 9)) (8.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.23.0->typer-slim->transformers>=4.35.0->-r requirements.txt (line 9)) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lawapaul/AI_Agentic_DL.git\n",
        "%cd AI_Agentic_DL\n",
        "!git checkout model-comparison\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmw2rGZ9MQS3",
        "outputId": "ca6a485f-8624-4d80-d97f-a2ae2e624200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_comparison.py  results\n"
          ]
        }
      ],
      "source": [
        "!ls experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s2rzHw8NCkf",
        "outputId": "da4fa769-2104-4717-8b9b-a1d86a1a947e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From https://github.com/lawapaul/AI_Agentic_DL\n",
            " * branch            model-comparison -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull origin model-comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sM866pxNEEZ",
        "outputId": "8ede2419-2d59-40bd-f948-a12c386ef8c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cnn_model.py\t    __init__.py       resnet_1d.py\n",
            "gru_model.py\t    lstm_model.py     trainer.py\n",
            "hybrid_cnn_lstm.py  model_factory.py  transformer_1d.py\n"
          ]
        }
      ],
      "source": [
        "!ls models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvTmemKE3Twh"
      },
      "source": [
        "#Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "BayaSqrcOJvn",
        "outputId": "da8aa171-6284-4173-9171-e9891a96b90b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b470f26b-d458-4dd1-a1c8-bc71660c3887\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b470f26b-d458-4dd1-a1c8-bc71660c3887\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"hss501\",\"key\":\"05c56fa04dc4e6c3879ca3f6e0ce351c\"}'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TCM3HOOf2acm"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wph_NLUY23Fy",
        "outputId": "733968e4-e3d2-4914-9b27-1fc28fbea6ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/chethuhn/network-intrusion-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading network-intrusion-dataset.zip to /content/AI_Agentic_DL\n",
            " 66% 151M/230M [00:00<00:00, 1.58GB/s]\n",
            "100% 230M/230M [00:00<00:00, 1.01GB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d chethuhn/network-intrusion-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-bycblQ2bV0",
        "outputId": "234b67cd-7dcd-465a-fb97-a883d2bb1806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "agent\t\tIDS_Colab_HuggingFace.ipynb    pipeline.py\n",
            "cleanup.sh\tllm\t\t\t       README.md\n",
            "data\t\tmodels\t\t\t       requirements.txt\n",
            "experiments\tnetwork-intrusion-dataset.zip\n",
            "explainability\tnotebooks\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K2UkDy_3LgA",
        "outputId": "78dc6ead-16b1-4f61-9323-44e2903f9106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  network-intrusion-dataset.zip\n",
            "  inflating: cicids2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv  \n",
            "  inflating: cicids2017/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv  \n",
            "  inflating: cicids2017/Friday-WorkingHours-Morning.pcap_ISCX.csv  \n",
            "  inflating: cicids2017/Monday-WorkingHours.pcap_ISCX.csv  \n",
            "  inflating: cicids2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv  \n",
            "  inflating: cicids2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv  \n",
            "  inflating: cicids2017/Tuesday-WorkingHours.pcap_ISCX.csv  \n",
            "  inflating: cicids2017/Wednesday-workingHours.pcap_ISCX.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip -o network-intrusion-dataset.zip -d cicids2017\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF8Hgwk93Nze",
        "outputId": "08156bf2-5035-44b2-d5d7-c2d697a0e480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
            "Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
            "Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
            "Monday-WorkingHours.pcap_ISCX.csv\n",
            "Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
            "Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
            "Tuesday-WorkingHours.pcap_ISCX.csv\n",
            "Wednesday-workingHours.pcap_ISCX.csv\n"
          ]
        }
      ],
      "source": [
        "!ls cicids2017\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQnd16ud3Qr-"
      },
      "source": [
        "#Merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7p7jl874Ubj",
        "outputId": "3ea5e38a-269f-4d38-cb75-665a03816372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading: cicids2017/Tuesday-WorkingHours.pcap_ISCX.csv\n",
            "Loading: cicids2017/Monday-WorkingHours.pcap_ISCX.csv\n",
            "Loading: cicids2017/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
            "Loading: cicids2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
            "Loading: cicids2017/Wednesday-workingHours.pcap_ISCX.csv\n",
            "Loading: cicids2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
            "Loading: cicids2017/Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
            "Loading: cicids2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
            "Final Shape: (2830743, 79)\n",
            "Column names sample: Index(['Destination Port', 'Flow Duration', 'Total Fwd Packets',\n",
            "       'Total Backward Packets', 'Total Length of Fwd Packets'],\n",
            "      dtype='object')\n",
            "Total Classes: 15\n",
            "\n",
            "Class Distribution:\n",
            "\n",
            "Label\n",
            "BENIGN                        2273097\n",
            "DoS Hulk                       231073\n",
            "PortScan                       158930\n",
            "DDoS                           128027\n",
            "DoS GoldenEye                   10293\n",
            "FTP-Patator                      7938\n",
            "SSH-Patator                      5897\n",
            "DoS slowloris                    5796\n",
            "DoS Slowhttptest                 5499\n",
            "Bot                              1966\n",
            "Web Attack � Brute Force         1507\n",
            "Web Attack � XSS                  652\n",
            "Infiltration                       36\n",
            "Web Attack � Sql Injection         21\n",
            "Heartbleed                         11\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "path = \"cicids2017/*.csv\"\n",
        "files = glob.glob(path)\n",
        "\n",
        "df_list = []\n",
        "\n",
        "for file in files:\n",
        "    print(\"Loading:\", file)\n",
        "    temp = pd.read_csv(file)\n",
        "    temp.columns = temp.columns.str.strip()\n",
        "\n",
        "    df_list.append(temp)\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "print(\"Final Shape:\", df.shape)\n",
        "print(\"Column names sample:\", df.columns[:5])\n",
        "print(\"Total Classes:\", df['Label'].nunique())\n",
        "print(\"\\nClass Distribution:\\n\")\n",
        "print(df['Label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsRGpcUu3jpH"
      },
      "source": [
        "#Model Comparison File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAgLtLOC4GrK",
        "outputId": "e5f1afac-7c91-467b-99a1-9d5b2ea78ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From https://github.com/lawapaul/AI_Agentic_DL\n",
            " * branch            model-comparison -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull origin model-comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOmihv3K4EC7"
      },
      "source": [
        "#Running Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlIj_uRsN66i",
        "outputId": "382f7954-4bcf-45dc-8e14-3bbe12db2019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-18 11:13:15.915056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771413195.935654    1632 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771413195.942416    1632 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771413195.959160    1632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771413195.959184    1632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771413195.959189    1632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771413195.959194    1632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-18 11:13:15.963738: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== MODEL COMPARISON EXPERIMENT (CICIDS2017) ===\n",
            "\n",
            "\n",
            "=== Loading CICIDS2017 Dataset (Memory Safe) ===\n",
            "\n",
            "Found files: 8\n",
            "Loading: cicids2017/Tuesday-WorkingHours.pcap_ISCX.csv\n",
            "Loading: cicids2017/Monday-WorkingHours.pcap_ISCX.csv\n",
            "Loading: cicids2017/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
            "Loading: cicids2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
            "Loading: cicids2017/Wednesday-workingHours.pcap_ISCX.csv\n",
            "Loading: cicids2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
            "Loading: cicids2017/Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
            "Loading: cicids2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
            "Original shape: (2827876, 79)\n",
            "Applying balanced sampling...\n",
            "After sampling: (99603, 79)\n",
            "Label\n",
            "BENIGN                        15000\n",
            "PortScan                      15000\n",
            "DoS Hulk                      15000\n",
            "DDoS                          15000\n",
            "DoS GoldenEye                 10293\n",
            "FTP-Patator                    7935\n",
            "SSH-Patator                    5897\n",
            "DoS slowloris                  5796\n",
            "DoS Slowhttptest               5499\n",
            "Bot                            1956\n",
            "Web Attack � Brute Force       1507\n",
            "Web Attack � XSS                652\n",
            "Infiltration                     36\n",
            "Web Attack � Sql Injection       21\n",
            "Heartbleed                       11\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Preprocessing Data ===\n",
            "\n",
            "Number of classes: 15\n",
            "Encoded classes: {'BENIGN': 0, 'Bot': 1, 'DDoS': 2, 'DoS GoldenEye': 3, 'DoS Hulk': 4, 'DoS Slowhttptest': 5, 'DoS slowloris': 6, 'FTP-Patator': 7, 'Heartbleed': 8, 'Infiltration': 9, 'PortScan': 10, 'SSH-Patator': 11, 'Web Attack � Brute Force': 12, 'Web Attack � Sql Injection': 13, 'Web Attack � XSS': 14}\n",
            "Train shape: (79682, 78, 1)\n",
            "Test shape: (19921, 78, 1)\n",
            "\n",
            "==============================\n",
            "Training CNN\n",
            "==============================\n",
            "\n",
            "=== Training IDS CNN Model ===\n",
            "Training samples: 79682\n",
            "Validation samples: 19921\n",
            "Batch size: 64\n",
            "Max epochs: 10\n",
            "Input shape after reshape: (79682, 78, 1)\n",
            "2026-02-18 11:13:48.832788: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1771413228.837768    1632 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Epoch 1/10\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1771413235.086769    1797 service.cc:152] XLA service 0x7bcab8004050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1771413235.086800    1797 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-18 11:13:55.266644: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1771413236.115860    1797 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2026-02-18 11:13:59.308114: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-18 11:13:59.602207: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.5 = (f32[64,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,256,1,78]{3,2,1,0} %bitcast.22216, f32[256,256,1,3]{3,2,1,0} %bitcast.22220), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-18 11:13:59.683984: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-18 11:13:59.788738: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.18711335s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.5 = (f32[64,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,256,1,78]{3,2,1,0} %bitcast.22216, f32[256,256,1,3]{3,2,1,0} %bitcast.22220), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-18 11:14:00.179999: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-18 11:14:00.458577: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-18 11:14:02.487513: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2026-02-18 11:14:02.641711: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "I0000 00:00:1771413249.042762    1797 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6823 - loss: 1.05302026-02-18 11:14:26.745049: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6827 - loss: 1.0519\n",
            "Epoch 1: val_accuracy improved from -inf to 0.38653, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 21ms/step - accuracy: 0.6828 - loss: 1.0516 - val_accuracy: 0.3865 - val_loss: 3.6875 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8962 - loss: 0.3432\n",
            "Epoch 2: val_accuracy improved from 0.38653 to 0.85894, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.8962 - loss: 0.3431 - val_accuracy: 0.8589 - val_loss: 0.4322 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9330 - loss: 0.2250\n",
            "Epoch 3: val_accuracy did not improve from 0.85894\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.9330 - loss: 0.2249 - val_accuracy: 0.8163 - val_loss: 0.6828 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m1244/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9355 - loss: 0.2140\n",
            "Epoch 4: val_accuracy did not improve from 0.85894\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - accuracy: 0.9355 - loss: 0.2140 - val_accuracy: 0.7573 - val_loss: 1.2333 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9406 - loss: 0.1989\n",
            "Epoch 5: val_accuracy did not improve from 0.85894\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.9406 - loss: 0.1989 - val_accuracy: 0.6752 - val_loss: 1.8861 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m1244/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9473 - loss: 0.1758\n",
            "Epoch 6: val_accuracy improved from 0.85894 to 0.95562, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.9473 - loss: 0.1757 - val_accuracy: 0.9556 - val_loss: 0.1477 - learning_rate: 5.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9575 - loss: 0.1407\n",
            "Epoch 7: val_accuracy did not improve from 0.95562\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.9575 - loss: 0.1407 - val_accuracy: 0.9498 - val_loss: 0.1857 - learning_rate: 5.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9527 - loss: 0.1630\n",
            "Epoch 8: val_accuracy did not improve from 0.95562\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.9527 - loss: 0.1629 - val_accuracy: 0.9151 - val_loss: 0.2773 - learning_rate: 5.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9569 - loss: 0.1421\n",
            "Epoch 9: val_accuracy did not improve from 0.95562\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.9569 - loss: 0.1421 - val_accuracy: 0.7252 - val_loss: 1.4233 - learning_rate: 5.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9601 - loss: 0.1310\n",
            "Epoch 10: val_accuracy improved from 0.95562 to 0.96632, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.9601 - loss: 0.1310 - val_accuracy: 0.9663 - val_loss: 0.1199 - learning_rate: 2.5000e-04\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.1199\n",
            "Test Accuracy: 0.9663\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.1199\n",
            "Test Accuracy: 0.9663\n",
            "\n",
            "==============================\n",
            "Training LSTM\n",
            "==============================\n",
            "\n",
            "=== Training IDS LSTM Model ===\n",
            "Training samples: 79682\n",
            "Validation samples: 19921\n",
            "Batch size: 64\n",
            "Max epochs: 10\n",
            "Input shape after reshape: (79682, 78, 1)\n",
            "Epoch 1/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6652 - loss: 1.0272\n",
            "Epoch 1: val_accuracy improved from -inf to 0.93936, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.6654 - loss: 1.0265 - val_accuracy: 0.9394 - val_loss: 0.2120 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9306 - loss: 0.2359\n",
            "Epoch 2: val_accuracy improved from 0.93936 to 0.95567, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9306 - loss: 0.2358 - val_accuracy: 0.9557 - val_loss: 0.1521 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9507 - loss: 0.1652\n",
            "Epoch 3: val_accuracy did not improve from 0.95567\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9507 - loss: 0.1652 - val_accuracy: 0.9553 - val_loss: 0.1505 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9562 - loss: 0.1419\n",
            "Epoch 4: val_accuracy did not improve from 0.95567\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9562 - loss: 0.1419 - val_accuracy: 0.9539 - val_loss: 0.1417 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9565 - loss: 0.1444\n",
            "Epoch 5: val_accuracy did not improve from 0.95567\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9565 - loss: 0.1444 - val_accuracy: 0.9480 - val_loss: 0.1494 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9623 - loss: 0.1223\n",
            "Epoch 6: val_accuracy improved from 0.95567 to 0.96416, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9623 - loss: 0.1223 - val_accuracy: 0.9642 - val_loss: 0.1189 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m1241/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9625 - loss: 0.1238\n",
            "Epoch 7: val_accuracy improved from 0.96416 to 0.96587, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9625 - loss: 0.1237 - val_accuracy: 0.9659 - val_loss: 0.1176 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9613 - loss: 0.1278\n",
            "Epoch 8: val_accuracy did not improve from 0.96587\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9613 - loss: 0.1278 - val_accuracy: 0.9658 - val_loss: 0.1127 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9685 - loss: 0.1033\n",
            "Epoch 9: val_accuracy improved from 0.96587 to 0.96637, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9685 - loss: 0.1033 - val_accuracy: 0.9664 - val_loss: 0.1152 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9704 - loss: 0.0993\n",
            "Epoch 10: val_accuracy improved from 0.96637 to 0.97068, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9704 - loss: 0.0993 - val_accuracy: 0.9707 - val_loss: 0.0984 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.0984\n",
            "Test Accuracy: 0.9707\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.0984\n",
            "Test Accuracy: 0.9707\n",
            "\n",
            "==============================\n",
            "Training GRU\n",
            "==============================\n",
            "\n",
            "=== Training IDS GRU Model ===\n",
            "Training samples: 79682\n",
            "Validation samples: 19921\n",
            "Batch size: 64\n",
            "Max epochs: 10\n",
            "Input shape after reshape: (79682, 78, 1)\n",
            "Epoch 1/10\n",
            "\u001b[1m1241/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6465 - loss: 1.0707\n",
            "Epoch 1: val_accuracy improved from -inf to 0.90026, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - accuracy: 0.6473 - loss: 1.0684 - val_accuracy: 0.9003 - val_loss: 0.3372 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9196 - loss: 0.2650\n",
            "Epoch 2: val_accuracy improved from 0.90026 to 0.93846, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9196 - loss: 0.2649 - val_accuracy: 0.9385 - val_loss: 0.1983 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m1241/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9380 - loss: 0.1984\n",
            "Epoch 3: val_accuracy improved from 0.93846 to 0.94709, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9381 - loss: 0.1983 - val_accuracy: 0.9471 - val_loss: 0.1680 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.1626\n",
            "Epoch 4: val_accuracy improved from 0.94709 to 0.95311, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9474 - loss: 0.1626 - val_accuracy: 0.9531 - val_loss: 0.1561 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m1241/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9521 - loss: 0.1473\n",
            "Epoch 5: val_accuracy improved from 0.95311 to 0.95598, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9521 - loss: 0.1473 - val_accuracy: 0.9560 - val_loss: 0.1371 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m1244/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9576 - loss: 0.1309\n",
            "Epoch 6: val_accuracy improved from 0.95598 to 0.96074, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9576 - loss: 0.1309 - val_accuracy: 0.9607 - val_loss: 0.1289 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9602 - loss: 0.1261\n",
            "Epoch 7: val_accuracy improved from 0.96074 to 0.96792, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9602 - loss: 0.1261 - val_accuracy: 0.9679 - val_loss: 0.1110 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9628 - loss: 0.1183\n",
            "Epoch 8: val_accuracy did not improve from 0.96792\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9628 - loss: 0.1183 - val_accuracy: 0.9641 - val_loss: 0.1193 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9642 - loss: 0.1121\n",
            "Epoch 9: val_accuracy did not improve from 0.96792\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9642 - loss: 0.1121 - val_accuracy: 0.9666 - val_loss: 0.1095 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9650 - loss: 0.1109\n",
            "Epoch 10: val_accuracy did not improve from 0.96792\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9650 - loss: 0.1109 - val_accuracy: 0.9663 - val_loss: 0.1083 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.1083\n",
            "Test Accuracy: 0.9663\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.1083\n",
            "Test Accuracy: 0.9663\n",
            "\n",
            "==============================\n",
            "Training HYBRID\n",
            "==============================\n",
            "\n",
            "=== Training IDS HYBRID Model ===\n",
            "Training samples: 79682\n",
            "Validation samples: 19921\n",
            "Batch size: 64\n",
            "Max epochs: 10\n",
            "Input shape after reshape: (79682, 78, 1)\n",
            "Epoch 1/10\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8892 - loss: 0.3842\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94433, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8892 - loss: 0.3841 - val_accuracy: 0.9443 - val_loss: 0.1643 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9569 - loss: 0.1442\n",
            "Epoch 2: val_accuracy improved from 0.94433 to 0.97124, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9570 - loss: 0.1440 - val_accuracy: 0.9712 - val_loss: 0.1023 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m1244/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9736 - loss: 0.0859\n",
            "Epoch 3: val_accuracy improved from 0.97124 to 0.97495, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9736 - loss: 0.0859 - val_accuracy: 0.9750 - val_loss: 0.0897 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9771 - loss: 0.0758\n",
            "Epoch 4: val_accuracy improved from 0.97495 to 0.97545, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9771 - loss: 0.0758 - val_accuracy: 0.9755 - val_loss: 0.0820 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m1240/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9761 - loss: 0.0751\n",
            "Epoch 5: val_accuracy improved from 0.97545 to 0.97726, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9761 - loss: 0.0751 - val_accuracy: 0.9773 - val_loss: 0.0742 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9791 - loss: 0.0647\n",
            "Epoch 6: val_accuracy improved from 0.97726 to 0.97766, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.9791 - loss: 0.0647 - val_accuracy: 0.9777 - val_loss: 0.0819 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9809 - loss: 0.0617\n",
            "Epoch 7: val_accuracy did not improve from 0.97766\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.0617 - val_accuracy: 0.9756 - val_loss: 0.0828 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9795 - loss: 0.0618\n",
            "Epoch 8: val_accuracy improved from 0.97766 to 0.98118, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9795 - loss: 0.0618 - val_accuracy: 0.9812 - val_loss: 0.0587 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9816 - loss: 0.0571\n",
            "Epoch 9: val_accuracy improved from 0.98118 to 0.98253, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.0571 - val_accuracy: 0.9825 - val_loss: 0.0576 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9826 - loss: 0.0543\n",
            "Epoch 10: val_accuracy did not improve from 0.98253\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9826 - loss: 0.0543 - val_accuracy: 0.9799 - val_loss: 0.0701 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.0576\n",
            "Test Accuracy: 0.9825\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.0576\n",
            "Test Accuracy: 0.9825\n",
            "\n",
            "==============================\n",
            "Training RESNET\n",
            "==============================\n",
            "\n",
            "=== Training IDS RESNET Model ===\n",
            "Training samples: 79682\n",
            "Validation samples: 19921\n",
            "Batch size: 64\n",
            "Max epochs: 10\n",
            "Input shape after reshape: (79682, 78, 1)\n",
            "Epoch 1/10\n",
            "2026-02-18 11:25:11.491481: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-18 11:25:11.721450: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8741 - loss: 0.4319\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87415, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - accuracy: 0.8741 - loss: 0.4317 - val_accuracy: 0.8742 - val_loss: 0.3323 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9702 - loss: 0.1019\n",
            "Epoch 2: val_accuracy improved from 0.87415 to 0.96928, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9702 - loss: 0.1019 - val_accuracy: 0.9693 - val_loss: 0.1176 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m1239/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.1059\n",
            "Epoch 3: val_accuracy did not improve from 0.96928\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.1058 - val_accuracy: 0.9600 - val_loss: 0.1193 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m1239/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9682 - loss: 0.1065\n",
            "Epoch 4: val_accuracy improved from 0.96928 to 0.98077, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9683 - loss: 0.1063 - val_accuracy: 0.9808 - val_loss: 0.0684 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9779 - loss: 0.0720\n",
            "Epoch 5: val_accuracy did not improve from 0.98077\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9779 - loss: 0.0719 - val_accuracy: 0.9805 - val_loss: 0.0765 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m1241/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9737 - loss: 0.0881\n",
            "Epoch 6: val_accuracy did not improve from 0.98077\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9737 - loss: 0.0880 - val_accuracy: 0.9798 - val_loss: 0.0766 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9707 - loss: 0.0939\n",
            "Epoch 7: val_accuracy did not improve from 0.98077\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9708 - loss: 0.0938 - val_accuracy: 0.9668 - val_loss: 0.0903 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m1241/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.0550\n",
            "Epoch 8: val_accuracy improved from 0.98077 to 0.98394, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0550 - val_accuracy: 0.9839 - val_loss: 0.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.0541\n",
            "Epoch 9: val_accuracy did not improve from 0.98394\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.0541 - val_accuracy: 0.8683 - val_loss: 0.4813 - learning_rate: 5.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.0474\n",
            "Epoch 10: val_accuracy improved from 0.98394 to 0.98404, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9844 - loss: 0.0474 - val_accuracy: 0.9840 - val_loss: 0.0582 - learning_rate: 5.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.0582\n",
            "Test Accuracy: 0.9840\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.0582\n",
            "Test Accuracy: 0.9840\n",
            "\n",
            "==============================\n",
            "Training TRANSFORMER\n",
            "==============================\n",
            "\n",
            "=== Training IDS TRANSFORMER Model ===\n",
            "Training samples: 79682\n",
            "Validation samples: 19921\n",
            "Batch size: 64\n",
            "Max epochs: 10\n",
            "Input shape after reshape: (79682, 78, 1)\n",
            "Epoch 1/10\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5782 - loss: 1.2619\n",
            "Epoch 1: val_accuracy improved from -inf to 0.83249, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - accuracy: 0.5783 - loss: 1.2616 - val_accuracy: 0.8325 - val_loss: 0.4909 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m1239/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8481 - loss: 0.4650\n",
            "Epoch 2: val_accuracy improved from 0.83249 to 0.89328, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.4646 - val_accuracy: 0.8933 - val_loss: 0.3201 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.3156\n",
            "Epoch 3: val_accuracy improved from 0.89328 to 0.91677, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8951 - loss: 0.3156 - val_accuracy: 0.9168 - val_loss: 0.2604 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m1243/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9172 - loss: 0.2557\n",
            "Epoch 4: val_accuracy improved from 0.91677 to 0.93514, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9172 - loss: 0.2557 - val_accuracy: 0.9351 - val_loss: 0.2298 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m1240/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.2466\n",
            "Epoch 5: val_accuracy did not improve from 0.93514\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9197 - loss: 0.2465 - val_accuracy: 0.9273 - val_loss: 0.2226 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m1242/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9290 - loss: 0.2220\n",
            "Epoch 6: val_accuracy did not improve from 0.93514\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9290 - loss: 0.2220 - val_accuracy: 0.9350 - val_loss: 0.2177 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9290 - loss: 0.2243\n",
            "Epoch 7: val_accuracy did not improve from 0.93514\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9290 - loss: 0.2243 - val_accuracy: 0.9283 - val_loss: 0.2124 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m1245/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9356 - loss: 0.2001\n",
            "Epoch 8: val_accuracy improved from 0.93514 to 0.94679, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9356 - loss: 0.2001 - val_accuracy: 0.9468 - val_loss: 0.1814 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m1237/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9383 - loss: 0.1982\n",
            "Epoch 9: val_accuracy did not improve from 0.94679\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9383 - loss: 0.1981 - val_accuracy: 0.9397 - val_loss: 0.1820 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m1241/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9407 - loss: 0.1845\n",
            "Epoch 10: val_accuracy improved from 0.94679 to 0.95387, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9407 - loss: 0.1845 - val_accuracy: 0.9539 - val_loss: 0.1633 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.1633\n",
            "Test Accuracy: 0.9539\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.1633\n",
            "Test Accuracy: 0.9539\n",
            "\n",
            "=== FINAL RESULTS ===\n",
            "         model  accuracy  ...  inference_time_per_sample_sec  parameters\n",
            "0          cnn  0.966317  ...                       0.000886      960015\n",
            "1         lstm  0.970684  ...                       0.000170      126223\n",
            "2          gru  0.966267  ...                       0.000171       97807\n",
            "3       hybrid  0.982531  ...                       0.000168      159247\n",
            "4       resnet  0.984037  ...                       0.000759      474383\n",
            "5  transformer  0.953868  ...                       0.001304       77327\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "\n",
            "Saved to model_comparison_results.csv\n"
          ]
        }
      ],
      "source": [
        "!python -m experiments.model_comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtTCVTKN8PRB"
      },
      "source": [
        "This experiment evaluated six deep learning architectures — CNN, LSTM, GRU, Hybrid CNN-LSTM, ResNet-1D, and Transformer — on a balanced subset (~100K samples) of the CICIDS2017 dataset containing 15 intrusion classes.\n",
        "\n",
        "All models were trained for 2 epochs under identical preprocessing and sampling conditions to ensure a fair architectural comparison.\n",
        "\n",
        "Key Findings\n",
        "\n",
        "Hybrid CNN-LSTM achieved the highest performance (97.41% accuracy), demonstrating superior ability to capture both spatial and sequential characteristics of network flow features.\n",
        "\n",
        "ResNet-1D (96.97%) performed comparably well but required significantly more parameters (~474K) than the Hybrid model (~159K), indicating lower parameter efficiency.\n",
        "\n",
        "GRU (92.38%) and LSTM (91.68%) showed strong sequential modeling capability and stable convergence, with GRU offering faster inference and fewer parameters.\n",
        "\n",
        "The standalone CNN architecture underperformed (55.47%), indicating that purely convolutional structures are insufficient for complex multi-class intrusion detection tasks in tabular flow data.\n",
        "\n",
        "The Transformer model (84.96%), while promising, did not converge fully within 2 epochs and likely requires longer training and hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR1Ngtt0hGX7",
        "outputId": "2a55968f-2b29-4a69-d518-9b99e55c5cf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model_Comparison_Experiment.ipynb\n"
          ]
        }
      ],
      "source": [
        "!ls notebooks/Model_Comparision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "33_XEFfzh5mV"
      },
      "outputs": [],
      "source": [
        "!mkdir -p experiments/results\n",
        "!mv model_comparison_results.csv experiments/results/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeBGLoANh6y7",
        "outputId": "100925e9-822c-4cc7-c7d1-9abba5428a5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_comparison_results.csv\n"
          ]
        }
      ],
      "source": [
        "!ls experiments/results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SLREomXMh8_U"
      },
      "outputs": [],
      "source": [
        "!git add notebooks/Model_Comparision/Model_Comparison_Experiment.ipynb\n",
        "!git add experiments/results/model_comparison_results.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhxV4QVDhu5x",
        "outputId": "1013d69b-02ca-4789-99e0-0f9f9ef50471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[model-comparison 7359c38] 10-epoch CICIDS2017 model comparison results\n",
            " 1 file changed, 7 insertions(+), 7 deletions(-)\n",
            " rewrite experiments/results/model_comparison_results.csv (87%)\n"
          ]
        }
      ],
      "source": [
        "!git commit -m \"10-epoch CICIDS2017 model comparison results\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-SPcsXBhIw2",
        "outputId": "a00fa8ce-6e5a-46c3-bb13-4a88cce35857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enumerating objects: 9, done.\n",
            "Counting objects:  11% (1/9)\rCounting objects:  22% (2/9)\rCounting objects:  33% (3/9)\rCounting objects:  44% (4/9)\rCounting objects:  55% (5/9)\rCounting objects:  66% (6/9)\rCounting objects:  77% (7/9)\rCounting objects:  88% (8/9)\rCounting objects: 100% (9/9)\rCounting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  20% (1/5)\rCompressing objects:  40% (2/5)\rCompressing objects:  60% (3/5)\rCompressing objects:  80% (4/5)\rCompressing objects: 100% (5/5)\rCompressing objects: 100% (5/5), done.\n",
            "Writing objects:  20% (1/5)\rWriting objects:  40% (2/5)\rWriting objects:  60% (3/5)\rWriting objects:  80% (4/5)\rWriting objects: 100% (5/5)\rWriting objects: 100% (5/5), 818 bytes | 818.00 KiB/s, done.\n",
            "Total 5 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas:   0% (0/1)\u001b[K\rremote: Resolving deltas: 100% (1/1)\u001b[K\rremote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "remote: This repository moved. Please use the new location:\u001b[K\n",
            "remote:   https://github.com/Lawapaul/AI_Agentic_DL.git\u001b[K\n",
            "To https://github.com/lawapaul/AI_Agentic_DL.git\n",
            "   e4e2377..7359c38  model-comparison -> model-comparison\n"
          ]
        }
      ],
      "source": [
        "!git push origin model-comparison"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
