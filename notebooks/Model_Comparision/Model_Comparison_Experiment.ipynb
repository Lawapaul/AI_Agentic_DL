{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMiAuJDPVmXImlpy8CAybSg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lawapaul/AI_Agentic_DL/blob/model-comparison/notebooks/Model_Comparision/Model_Comparison_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSzA0pPLMGrd",
        "outputId": "773b7272-7864-4878-9d28-926d86f9ca33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI_Agentic_DL'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 115 (delta 44), reused 92 (delta 25), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (115/115), 63.70 KiB | 4.90 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n",
            "/content/AI_Agentic_DL\n",
            "Branch 'model-comparison' set up to track remote branch 'model-comparison' from 'origin'.\n",
            "Switched to a new branch 'model-comparison'\n",
            "Requirement already satisfied: tensorflow>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.19.0)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: shap>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.50.0)\n",
            "Requirement already satisfied: kagglehub>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.3.13)\n",
            "Requirement already satisfied: transformers>=4.35.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (5.0.0)\n",
            "Requirement already satisfied: accelerate>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.12.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.9.0+cu128)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (5.29.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.5.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 2)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 3)) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (4.67.3)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap>=0.42.0->-r requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub>=0.1.0->-r requirements.txt (line 8)) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.24.0->-r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.46.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (1.5.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap>=0.42.0->-r requirements.txt (line 7)) (0.43.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->-r requirements.txt (line 11)) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers>=4.35.0->-r requirements.txt (line 9)) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.35.0->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 1)) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lawapaul/AI_Agentic_DL.git\n",
        "%cd AI_Agentic_DL\n",
        "!git checkout model-comparison\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls experiments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmw2rGZ9MQS3",
        "outputId": "5572d962-1858-4d29-be1e-c91e343ef1ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_comparison.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,200p' models/model_factory.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyRdOHC7MSwi",
        "outputId": "83accff5-15eb-4339-bcd0-bd2abcdbba66"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from models.cnn_model import build_ids_cnn_model\n",
            "from models.hybrid_cnn_lstm import build_hybrid_model\n",
            "from models.lstm_model import build_lstm_model\n",
            "from models.gru_model import build_gru_model\n",
            "from models.resnet_1d import build_resnet_model\n",
            "from models.transformer_1d import build_transformer_model\n",
            "\n",
            "def get_model(model_type, input_shape, num_classes):\n",
            "\n",
            "    if model_type == \"cnn\":\n",
            "        return build_ids_cnn_model(input_shape, num_classes)\n",
            "\n",
            "    elif model_type == \"hybrid\":\n",
            "        return build_hybrid_model(input_shape, num_classes)\n",
            "\n",
            "    elif model_type == \"lstm\":\n",
            "        return build_lstm_model(input_shape, num_classes)\n",
            "\n",
            "    elif model_type == \"gru\":\n",
            "        return build_gru_model(input_shape, num_classes)\n",
            "\n",
            "    elif model_type == \"resnet\":\n",
            "        return build_resnet_model(input_shape, num_classes)\n",
            "\n",
            "    elif model_type == \"transformer\":\n",
            "        return build_transformer_model(input_shape, num_classes)\n",
            "\n",
            "    else:\n",
            "        raise ValueError(f\"Unknown model type: {model_type}\")"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin model-comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s2rzHw8NCkf",
        "outputId": "18f1032f-674b-4866-e17f-1ead5ff4c4c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/lawapaul/AI_Agentic_DL\n",
            " * branch            model-comparison -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sM866pxNEEZ",
        "outputId": "3bfe9830-0bdb-4979-b883-0b8fa1475fab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn_model.py\t    __init__.py       resnet_1d.py\n",
            "gru_model.py\t    lstm_model.py     trainer.py\n",
            "hybrid_cnn_lstm.py  model_factory.py  transformer_1d.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub\n",
        "import kagglehub\n",
        "kagglehub.dataset_download(\"solarmainframe/ids-intrusion-csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "BayaSqrcOJvn",
        "outputId": "1de9e6c4-7439-4bd2-ea18-1521eb1e061d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (26.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2026.1.4)\n",
            "Using Colab cache for faster access to the 'ids-intrusion-csv' dataset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/input/ids-intrusion-csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m experiments.model_comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlIj_uRsN66i",
        "outputId": "9d33c356-0b71-4435-e631-b869222e675b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-15 16:59:24.144412: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1771174764.164678     505 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1771174764.171254     505 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1771174764.186955     505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771174764.186979     505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771174764.186985     505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1771174764.186988     505 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-15 16:59:24.191366: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "=== MODEL COMPARISON EXPERIMENT ===\n",
            "\n",
            "Loading IDS dataset...\n",
            "Found dataset path: /kaggle/input/ids-intrusion-csv\n",
            "Loading CSV file: /kaggle/input/ids-intrusion-csv/02-28-2018.csv\n",
            "Dataset loaded: 613104 samples, 80 columns\n",
            "\n",
            "=== Starting Preprocessing ===\n",
            "Separated labels: 613104 samples\n",
            "Feature columns: 79\n",
            "Unique attack types: 3\n",
            "Attack distribution:\n",
            "Label\n",
            "Benign           544200\n",
            "Infilteration     68871\n",
            "Label                33\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Converting features to numeric...\n",
            "Converted 79 columns to numeric\n",
            "\n",
            "Dropping fully-NaN columns...\n",
            "Columns after dropping fully-NaN: 78\n",
            "\n",
            "Dropping rows with NaN values...\n",
            "Rows before: 613104, after: 609030\n",
            "Dropped 4074 rows with NaN\n",
            "\n",
            "Final feature count: 78\n",
            "\n",
            "Encoding labels...\n",
            "Label mapping: {0: 'Benign', 1: 'Infilteration'}\n",
            "\n",
            "Handling infinity and extreme values...\n",
            "Dropped 2128 rows with infinity values\n",
            "Cleaned data shape: (606902, 78)\n",
            "\n",
            "Scaling features...\n",
            "Features scaled: mean=0.0000, std=0.9473\n",
            "\n",
            "Splitting data: 80% train, 20% test\n",
            "Train set: 485521 samples\n",
            "Test set: 121381 samples\n",
            "\n",
            "Reshaping for 1D CNN...\n",
            "Train shape: (485521, 78, 1)\n",
            "Test shape: (121381, 78, 1)\n",
            "\n",
            "=== Preprocessing Complete ===\n",
            "\n",
            "==============================\n",
            "Training CNN\n",
            "==============================\n",
            "\n",
            "=== Training IDS CNN Model ===\n",
            "Training samples: 485521\n",
            "Validation samples: 121381\n",
            "Batch size: 256\n",
            "Max epochs: 2\n",
            "Input shape after reshape: (485521, 78, 1)\n",
            "2026-02-15 17:00:12.284054: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1771174812.286938     505 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Epoch 1/2\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1771174819.218830     749 service.cc:152] XLA service 0x79d618010b30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1771174819.218858     749 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-15 17:00:19.391679: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1771174820.114064     749 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2026-02-15 17:00:22.832053: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng12{k11=2} for conv %cudnn-conv-bias-activation.36 = (f32[256,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,128,1,78]{3,2,1,0} %bitcast.19069, f32[256,128,1,3]{3,2,1,0} %bitcast.19073, f32[256]{0} %bitcast.23332), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"IDS_CNN_1/residual_cnn_block_1_2/cnn_block_2_1/conv1d_3_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:00:24.120357: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.288401449s\n",
            "Trying algorithm eng12{k11=2} for conv %cudnn-conv-bias-activation.36 = (f32[256,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,128,1,78]{3,2,1,0} %bitcast.19069, f32[256,128,1,3]{3,2,1,0} %bitcast.19073, f32[256]{0} %bitcast.23332), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"IDS_CNN_1/residual_cnn_block_1_2/cnn_block_2_1/conv1d_3_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:00:24.274093: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2026-02-15 17:00:24.495330: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 24.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2026-02-15 17:00:25.115137: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2026-02-15 17:00:25.115210: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2026-02-15 17:00:26.184320: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=2} for conv %cudnn-conv-bw-input.6 = (f32[256,128,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,256,1,78]{3,2,1,0} %bitcast.22343, f32[256,128,1,3]{3,2,1,0} %bitcast.22347), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_1_2/cnn_block_2_1/conv1d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:00:27.396315: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.212112152s\n",
            "Trying algorithm eng4{k11=2} for conv %cudnn-conv-bw-input.6 = (f32[256,128,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,256,1,78]{3,2,1,0} %bitcast.22343, f32[256,128,1,3]{3,2,1,0} %bitcast.22347), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_1_2/cnn_block_2_1/conv1d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:00:28.102846: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 17:00:28.396553: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.6 = (f32[256,128,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,256,1,78]{3,2,1,0} %bitcast.22343, f32[256,128,1,3]{3,2,1,0} %bitcast.22347), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_1_2/cnn_block_2_1/conv1d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:00:28.643244: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 17:00:28.894572: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.498117439s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.6 = (f32[256,128,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,256,1,78]{3,2,1,0} %bitcast.22343, f32[256,128,1,3]{3,2,1,0} %bitcast.22347), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_1_2/cnn_block_2_1/conv1d_3_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:00:29.324092: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 17:00:29.609547: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 17:00:32.360813: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng18{k11=0} for conv %cudnn-conv-bw-filter.9 = (f32[256,128,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,128,1,78]{3,2,1,0} %bitcast.19069, f32[256,256,1,78]{3,2,1,0} %bitcast.22328), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_1_2/conv1d_4_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:00:32.560113: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.199398229s\n",
            "Trying algorithm eng18{k11=0} for conv %cudnn-conv-bw-filter.9 = (f32[256,128,1,1]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,128,1,78]{3,2,1,0} %bitcast.19069, f32[256,256,1,78]{3,2,1,0} %bitcast.22328), window={size=1x1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/IDS_CNN_1/residual_cnn_block_1_2/conv1d_4_1/convolution/Conv2DBackpropFilter\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:00:33.397114: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 24.43GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "I0000 00:00:1771174839.569509     749 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m1896/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8719 - loss: 0.40562026-02-15 17:02:09.571168: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 17:02:09.765034: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng12{k11=2} for conv %cudnn-conv-bias-activation.38 = (f32[145,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[145,256,1,78]{3,2,1,0} %bitcast.19956, f32[256,256,1,3]{3,2,1,0} %bitcast.19960, f32[256]{0} %bitcast.23674), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:02:10.199189: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 17:02:10.531463: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.766520063s\n",
            "Trying algorithm eng12{k11=2} for conv %cudnn-conv-bias-activation.38 = (f32[145,256,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[145,256,1,78]{3,2,1,0} %bitcast.19956, f32[256,256,1,3]{3,2,1,0} %bitcast.19960, f32[256]{0} %bitcast.23674), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"IDS_CNN_1/residual_cnn_block_2_1/cnn_block_3_1/conv1d_5_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:02:10.700530: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 20.87GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2026-02-15 17:02:13.120536: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8719 - loss: 0.4056\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88757, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 58ms/step - accuracy: 0.8719 - loss: 0.4055 - val_accuracy: 0.8876 - val_loss: 0.3600 - learning_rate: 0.0010\n",
            "Epoch 2/2\n",
            "\u001b[1m1896/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8880 - loss: 0.3511\n",
            "Epoch 2: val_accuracy did not improve from 0.88757\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 50ms/step - accuracy: 0.8880 - loss: 0.3511 - val_accuracy: 0.8876 - val_loss: 0.3503 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3503\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3503\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "==============================\n",
            "Training LSTM\n",
            "==============================\n",
            "\n",
            "=== Training IDS LSTM Model ===\n",
            "Training samples: 485521\n",
            "Validation samples: 121381\n",
            "Batch size: 256\n",
            "Max epochs: 2\n",
            "Input shape after reshape: (485521, 78, 1)\n",
            "Epoch 1/2\n",
            "\u001b[1m1894/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8853 - loss: 0.3640\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88757, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 16ms/step - accuracy: 0.8853 - loss: 0.3640 - val_accuracy: 0.8876 - val_loss: 0.3505 - learning_rate: 0.0010\n",
            "Epoch 2/2\n",
            "\u001b[1m1894/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8869 - loss: 0.3548\n",
            "Epoch 2: val_accuracy did not improve from 0.88757\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - accuracy: 0.8869 - loss: 0.3548 - val_accuracy: 0.8876 - val_loss: 0.3520 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3505\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3505\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "==============================\n",
            "Training GRU\n",
            "==============================\n",
            "\n",
            "=== Training IDS GRU Model ===\n",
            "Training samples: 485521\n",
            "Validation samples: 121381\n",
            "Batch size: 256\n",
            "Max epochs: 2\n",
            "Input shape after reshape: (485521, 78, 1)\n",
            "Epoch 1/2\n",
            "\u001b[1m1896/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8862 - loss: 0.3637\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88757, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 15ms/step - accuracy: 0.8862 - loss: 0.3637 - val_accuracy: 0.8876 - val_loss: 0.3510 - learning_rate: 0.0010\n",
            "Epoch 2/2\n",
            "\u001b[1m1894/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8877 - loss: 0.3521\n",
            "Epoch 2: val_accuracy did not improve from 0.88757\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - accuracy: 0.8877 - loss: 0.3521 - val_accuracy: 0.8876 - val_loss: 0.3512 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3510\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3510\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "==============================\n",
            "Training HYBRID\n",
            "==============================\n",
            "\n",
            "=== Training IDS HYBRID Model ===\n",
            "Training samples: 485521\n",
            "Validation samples: 121381\n",
            "Batch size: 256\n",
            "Max epochs: 2\n",
            "Input shape after reshape: (485521, 78, 1)\n",
            "Epoch 1/2\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8848 - loss: 0.3536\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88757, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - accuracy: 0.8848 - loss: 0.3536 - val_accuracy: 0.8876 - val_loss: 0.3443 - learning_rate: 0.0010\n",
            "Epoch 2/2\n",
            "\u001b[1m1894/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8877 - loss: 0.3447\n",
            "Epoch 2: val_accuracy did not improve from 0.88757\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8877 - loss: 0.3447 - val_accuracy: 0.8876 - val_loss: 0.3434 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3434\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3434\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "==============================\n",
            "Training RESNET\n",
            "==============================\n",
            "\n",
            "=== Training IDS RESNET Model ===\n",
            "Training samples: 485521\n",
            "Validation samples: 121381\n",
            "Batch size: 256\n",
            "Max epochs: 2\n",
            "Input shape after reshape: (485521, 78, 1)\n",
            "Epoch 1/2\n",
            "2026-02-15 17:10:01.014949: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng12{k11=2} for conv %cudnn-conv-bias-activation.37 = (f32[256,128,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,128,1,78]{3,2,1,0} %bitcast.9487, f32[128,128,1,3]{3,2,1,0} %bitcast.9491, f32[128]{0} %bitcast.12449), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"IDS_RESNET_1D_1/conv1d_14_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:10:01.594795: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.579936123s\n",
            "Trying algorithm eng12{k11=2} for conv %cudnn-conv-bias-activation.37 = (f32[256,128,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,128,1,78]{3,2,1,0} %bitcast.9487, f32[128,128,1,3]{3,2,1,0} %bitcast.9491, f32[128]{0} %bitcast.12449), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"IDS_RESNET_1D_1/conv1d_14_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:10:02.678608: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=2} for conv %cudnn-conv-bw-input.8 = (f32[256,128,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,128,1,78]{3,2,1,0} %bitcast.10968, f32[128,128,1,3]{3,2,1,0} %bitcast.10972), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_RESNET_1D_1/conv1d_14_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:10:03.270424: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.591908107s\n",
            "Trying algorithm eng4{k11=2} for conv %cudnn-conv-bw-input.8 = (f32[256,128,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,128,1,78]{3,2,1,0} %bitcast.10968, f32[128,128,1,3]{3,2,1,0} %bitcast.10972), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_RESNET_1D_1/conv1d_14_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:10:03.752025: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 17:10:04.132623: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2026-02-15 17:10:04.270639: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.8 = (f32[256,128,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,128,1,78]{3,2,1,0} %bitcast.10968, f32[128,128,1,3]{3,2,1,0} %bitcast.10972), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_RESNET_1D_1/conv1d_14_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "2026-02-15 17:10:04.298143: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.027597781s\n",
            "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.8 = (f32[256,128,1,78]{3,2,1,0}, u8[0]{0}) custom-call(f32[256,128,1,78]{3,2,1,0} %bitcast.10968, f32[128,128,1,3]{3,2,1,0} %bitcast.10972), window={size=1x3 pad=0_0x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/IDS_RESNET_1D_1/conv1d_14_1/convolution/Conv2DBackpropInput\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8866 - loss: 0.3574\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88757, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 31ms/step - accuracy: 0.8866 - loss: 0.3574 - val_accuracy: 0.8876 - val_loss: 0.3451 - learning_rate: 0.0010\n",
            "Epoch 2/2\n",
            "\u001b[1m1896/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8869 - loss: 0.3478\n",
            "Epoch 2: val_accuracy did not improve from 0.88757\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 26ms/step - accuracy: 0.8869 - loss: 0.3478 - val_accuracy: 0.8876 - val_loss: 0.3443 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3443\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3443\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "==============================\n",
            "Training TRANSFORMER\n",
            "==============================\n",
            "\n",
            "=== Training IDS TRANSFORMER Model ===\n",
            "Training samples: 485521\n",
            "Validation samples: 121381\n",
            "Batch size: 256\n",
            "Max epochs: 2\n",
            "Input shape after reshape: (485521, 78, 1)\n",
            "Epoch 1/2\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8839 - loss: 0.3623\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88757, saving model to saved_models/ids_model.keras\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 19ms/step - accuracy: 0.8839 - loss: 0.3623 - val_accuracy: 0.8876 - val_loss: 0.3527 - learning_rate: 0.0010\n",
            "Epoch 2/2\n",
            "\u001b[1m1894/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8870 - loss: 0.3544\n",
            "Epoch 2: val_accuracy did not improve from 0.88757\n",
            "\u001b[1m1897/1897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - accuracy: 0.8870 - loss: 0.3544 - val_accuracy: 0.8876 - val_loss: 0.3525 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3525\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "=== Evaluating Model ===\n",
            "Test Loss: 0.3525\n",
            "Test Accuracy: 0.8876\n",
            "\n",
            "=== FINAL RESULTS ===\n",
            "         model  accuracy  ...  inference_time_per_sample_sec  parameters\n",
            "0          cnn  0.887569  ...                       0.001080      958338\n",
            "1         lstm  0.887569  ...                       0.000195      124546\n",
            "2          gru  0.887569  ...                       0.000366       96130\n",
            "3       hybrid  0.887569  ...                       0.000232      157570\n",
            "4       resnet  0.887569  ...                       0.000843      472706\n",
            "5  transformer  0.887569  ...                       0.001321       75650\n",
            "\n",
            "[6 rows x 6 columns]\n",
            "\n",
            "Saved to model_comparison_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p experiments/results"
      ],
      "metadata": {
        "id": "Bgb4xt3RTq1a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9mH-igFTtCa",
        "outputId": "f0116739-a149-4330-df18-45423b37ff77"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agent\t     explainability\t\t   models\trequirements.txt\n",
            "cleanup.sh   IDS_Colab_HuggingFace.ipynb   notebooks\tsaved_models\n",
            "data\t     llm\t\t\t   pipeline.py\n",
            "experiments  model_comparison_results.csv  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/AI_Agentic_DL\n",
        "!mkdir -p experiments/results\n",
        "!mv model_comparison_results.csv experiments/results/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4e1iGEvTyl_",
        "outputId": "bf6b7b73-a0dc-408d-eb5c-5dd37804aa34"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AI_Agentic_DL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls experiments\n",
        "!ls experiments/results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2ofHKyqT1bf",
        "outputId": "0ee77127-ced0-4ad4-881f-452179df7e99"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_comparison.py  __pycache__  results\n",
            "model_comparison_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add experiments/\n",
        "!git commit -m \"Add model comparison experiment results\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL7bD3LkT6he",
        "outputId": "f5473ac5-4d1d-4edc-ffff-453aa059c0b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[model-comparison 8868f88] Add model comparison experiment results\n",
            " 1 file changed, 7 insertions(+)\n",
            " create mode 100644 experiments/results/model_comparison_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"Harshit Singh\"\n",
        "!git config --global user.email \"harshitshekhawat501@gmail.com\"\n",
        "\n",
        "!git push origin model-comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K6TQgiuUqGH",
        "outputId": "eb3a99f7-da2e-429c-f32e-79d60427f51c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 7, done.\n",
            "Counting objects:  14% (1/7)\rCounting objects:  28% (2/7)\rCounting objects:  42% (3/7)\rCounting objects:  57% (4/7)\rCounting objects:  71% (5/7)\rCounting objects:  85% (6/7)\rCounting objects: 100% (7/7)\rCounting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  20% (1/5)\rCompressing objects:  40% (2/5)\rCompressing objects:  60% (3/5)\rCompressing objects:  80% (4/5)\rCompressing objects: 100% (5/5)\rCompressing objects: 100% (5/5), done.\n",
            "Writing objects:  20% (1/5)\rWriting objects:  40% (2/5)\rWriting objects:  60% (3/5)\rWriting objects:  80% (4/5)\rWriting objects: 100% (5/5)\rWriting objects: 100% (5/5), 733 bytes | 733.00 KiB/s, done.\n",
            "Total 5 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas:   0% (0/1)\u001b[K\rremote: Resolving deltas: 100% (1/1)\u001b[K\rremote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/Lawapaul/AI_Agentic_DL.git\n",
            "   c3a298a..8868f88  model-comparison -> model-comparison\n"
          ]
        }
      ]
    }
  ]
}